GPT model + NAZHA(或者其他中文预训练模型) pre-train model weights 微调GPT模型进行生成任务.

代码结构：
    
    1. src --- 存储所有源码，包括models, data processing, training, inference ...
    2. data --- 存储说有数据文件